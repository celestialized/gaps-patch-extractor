{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This jupyter notebook allows you to extract diffrent patch sizes from the GAPS dataset\n",
    "\n",
    "\n",
    "<a href=\"https://www.tu-ilmenau.de/en/neurob/data-sets-code/gaps/\">Link to GAPS dataset</a>\n",
    "\n",
    "\n",
    "<pre>\n",
    "@inproceedings{eisenbach2017how,\n",
    "  title={How to Get Pavement Distress Detection Ready for Deep Learning? A Systematic Approach.},\n",
    "  author={Eisenbach, Markus and Stricker, Ronny and Seichter, Daniel and Amende, Karl and Debes, Klaus\n",
    "          and Sesselmann, Maximilian and Ebersbach, Dirk and Stoeckert, Ulrike\n",
    "          and Gross, Horst-Michael},\n",
    "  booktitle={International Joint Conference on Neural Networks (IJCNN)},\n",
    "  pages={2039--2047},\n",
    "  year={2017}\n",
    "} </pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please install all the required packages before running the first cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from gaps_dataset import gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '' #replace this with your datadirectory\n",
    "login = '' #replace this with your login credentials"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gaps.download_images(login=login, datadir=datadir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After this step images.zip file shall be downloaded to your datadir. Extract the images.zip folder into your datadir such that following structure is created.\n",
    "\n",
    "datadir\n",
    " -images/ (contains all the GAPS images)\n",
    " -patch_references_test.npy\n",
    " -patch_references_train.npy\n",
    " -patch_references_valid.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the required folders where the patches will be extracted\n",
    "\n",
    "ps = 256 #define the patch size\n",
    "\n",
    "os.mkdir(os.path.join(datadir,'Subsets{0}'.format(ps)))\n",
    "subsetlist = ['train','test','valid']\n",
    "categorylist = ['Crack','Nocrack']\n",
    "for s in subsetlist:\n",
    "    os.mkdir(os.path.join(datadir,'Subsets{0}'.format(ps),s))\n",
    "    for c in categorylist:\n",
    "        os.mkdir(os.path.join(datadir,'Subsets{0}'.format(ps),s,c))\n",
    "os.mkdir(os.path.join(datadir,'masks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = os.path.join(datadir,'masks')\n",
    "for subset in ['train','test','valid']:\n",
    "    patch_ref = np.load(os.path.join(datadir,'patch_references_'+subset+'.npy')).astype(int)\n",
    "    columns = ['image_index', 'row', 'col', 'mirror_state', 'binary_label', 'class_label']\n",
    "    datatype = ['uint16', 'uint16', 'uint16','bool','bool',\"uint8\"]\n",
    "    datadf = pd.DataFrame(data= {columns[i]:patch_ref[:,i].astype(datatype[i]) for i in range(len(columns))})\n",
    "    datadf.class_label = datadf.class_label.astype('category')\n",
    "    groupeddf = datadf.groupby(by=['image_index'])\n",
    "    print(subset+' Start')\n",
    "    for group,data in groupeddf:\n",
    "        openpath = os.path.join(datadir,'images',subset,'_{:04d}.jpg'.format(group))\n",
    "        masksavename = subset+'_{:04d}.npy'.format(group)\n",
    "        I = cv2.imread(openpath)\n",
    "        maskI = np.zeros((1080,1920),dtype='bool')\n",
    "        for i in range(len(data)):\n",
    "            row = data.row.iloc[i]\n",
    "            col = data.col.iloc[i]\n",
    "            binary_label = data.binary_label.iloc[i]\n",
    "            maskI[row:row+64, col:col+64] = binary_label\n",
    "        np.save(os.path.join(mpath,masksavename),maskI)\n",
    "    print(subset+' Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmanager = pd.DataFrame(columns=['img_name','category','score','label'])\n",
    "masklist = sorted(os.listdir(os.path.join(datadir,'masks')))\n",
    "print('Start')\n",
    "i=0\n",
    "for mask in masklist:\n",
    "    openpath = os.path.join(datadir,'images',mask.split('.')[0]+'.jpg')\n",
    "    maskpath = os.path.join(datadir,'masks',mask)\n",
    "    bcpath = os.path.join(datadir,'Subsets256',mask.split('_')[0],'Crack')\n",
    "    bncpath = os.path.join(datadir,'Subsets256',mask.split('_')[0],'Nocrack')\n",
    "    I = cv2.imread(openpath)\n",
    "    maskI = np.load(maskpath)\n",
    "    for row in range(1080//ps):\n",
    "        for col in range(1920//ps):\n",
    "            masksubset = maskI[ps*row:ps*(row+1), ps*col:ps*(col+1)]\n",
    "            score = np.sum(masksubset)\n",
    "            if score>0:\n",
    "                savename = bcpath+'{0:04d}_{1}_{2}.jpg'.format(int(mask.split('_')[1].split('.')[0]),row,col)\n",
    "            else:\n",
    "                savename = bncpath+'{0:04d}_{1}_{2}.jpg'.format(int(mask.split('_')[1].split('.')[0]),row,col)\n",
    "            cv2.imwrite(savename,I[ps*row:ps*(row+1), ps*col:ps*(col+1)])\n",
    "            labelmanager.loc[i] = [savename,mask.split('_')[0],score,bool(score)]\n",
    "            i=i+1\n",
    "labelmanager.to_csv(os.path.join(datadir,'labels.csv'))\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnomalyDetection",
   "language": "python",
   "name": "anomaly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
